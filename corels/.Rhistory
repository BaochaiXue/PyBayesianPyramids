}
repmat = function(X,m,n){
mx = dim(X)[1]
nx = dim(X)[2]
matrix(t(matrix(X,mx,nx*n)),mx*m,nx*n,byrow=T)}
#####################
set.seed(0513)
K = 8
err_prob = 0.2
c = rep(1-err_prob, J)
g = rep(err_prob, J)
Q_block = matrix(0, nrow=3*K, ncol=K)
for (k in 1:K) {
Q_block[k, k] = 1
Q_block[K+k, k] = 1
Q_block[2*K+k, k] = 1
if (k<K) {
Q_block[K+k, k+1] = 1
Q_block[2*K+k, k+1] = 1
}
}
J = 120
Q = repmat(Q_block, J/(3*K), 1)
ind = sample(1:(2^K), 10, replace = FALSE, prob = NULL)
p = rep(0, 2^K)
p[ind] = 1/length(ind)
N = 1200
Alpha = as.matrix(expand.grid(rep(list(0:1), K)))
data = generate_X_DINA(Q, Alpha, N, p, c, g)
g
set.seed(0513)
K = 8
J = 120
err_prob = 0.2
c = rep(1-err_prob, J)
g = rep(err_prob, J)
Q_block = matrix(0, nrow=3*K, ncol=K)
for (k in 1:K) {
Q_block[k, k] = 1
Q_block[K+k, k] = 1
Q_block[2*K+k, k] = 1
if (k<K) {
Q_block[K+k, k+1] = 1
Q_block[2*K+k, k+1] = 1
}
}
Q = repmat(Q_block, J/(3*K), 1)
ind = sample(1:(2^K), 10, replace = FALSE, prob = NULL)
p = rep(0, 2^K)
p[ind] = 1/length(ind)
N = 1200
Alpha = as.matrix(expand.grid(rep(list(0:1), K)))
data = generate_X_DINA(Q, Alpha, N, p, c, g)
mod2 <- CDM::gdina( data, Q, rule="DINA" )
Alpha_mat[ind,]
Alpha[mat,]
Alpha[ind,]
ind = c(1,   129,   193,   225,   241,
249,   253,   254,   255,   256)
p = rep(0, 2^K)
p[ind] = 1/length(ind)
N = 1200
Alpha = as.matrix(expand.grid(rep(list(0:1), K)))
data = generate_X_DINA(Q, Alpha, N, p, c, g)
mod2 <- CDM::gdina( data, Q, rule="DINA" )
summary(mod2)
library(BiocFileCache)
bfc <- BiocFileCache("raw_data", ask = FALSE)
lun.zip <- bfcrpath(bfc,
file.path("https://www.ebi.ac.uk/arrayexpress/files",
"E-MTAB-5522/E-MTAB-5522.processed.1.zip"))
lun.sdrf <- bfcrpath(bfc,
file.path("https://www.ebi.ac.uk/arrayexpress/files",
"E-MTAB-5522/E-MTAB-5522.sdrf.txt"))
unzip(lun.zip, exdir=tempdir())
install.packages("BiocFileCache")
browseVignettes("BiocFileCache")
install.packages("BiocFileCache")
data(data.timss03.G8.su, package="CDM")
q.matrix <- data.timss03.G8.su$q.matrix
q.matrix
install.packages("rstan")
library(rstan)
setwd("/Users/yuqi/Dropbox/Research20/Works/WithAritra/robust-rpm-public-master/skewnormal")
source("skewnormal.data.R")
dim(X)
View(X)
install.packages(c("knitr", "rstanarm", "tidyr", "tidyverse"))
install.packages(c("knitr", "rstanarm", "tidyr", "tidyverse"))
#
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
#
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(fig.align = "center", echo = TRUE)
tumors <- read.csv(file = url("http://www.stat.columbia.edu/~gelman/book/data/rats.asc"),
skip = 2, header = T, sep = " ")[,c(1,2)]
y <- tumors$y
N <- tumors$N
n <- length(y)
#
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
#
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(fig.align = "center", echo = TRUE)
#
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
#
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(fig.align = "center", echo = TRUE)
tumors <- read.csv(file = url("http://www.stat.columbia.edu/~gelman/book/data/rats.asc"),
skip = 2, header = T, sep = " ")[,c(1,2)]
y <- tumors$y
N <- tumors$N
n <- length(y)
View(tumors)
install.packages("TruncatedNormal")
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
histo(rnorm(n=nSamples, mean=0, sd=1))
hist(rnorm(n=nSamples, mean=0, sd=1))
nSamples = 1000
hist(rnorm(n=nSamples, mean=0, sd=1))
nSamples = 10000
hist(rnorm(n=nSamples, mean=0, sd=1))
qnorm(p=0.95)
# step 1 - draw random samples
rnorm(n, mean=0, sd=1)
qnorm(p=0.95)
nSamples = 10000
hist(rnorm(n=nSamples, mean=0, sd=1))
hist(rexp(n = nSamples, rate = 1))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# step 1 - draw random samples
qnorm(p=0.95)
nSamples = 10000
hist(rnorm(n=nSamples, mean=0, sd=1))
hist(rexp(n = nSamples, rate = 1))
compute_MC_normal_mean = function(nSamples, mean, sd){
# step 1 - draw nSamples from the normal distribution
samples = rnorm(n=nSamples, mean=mean, sd=sd)
# step 2 - compute the quantity h(x)
MC_estimate = mean(samples)
# step 3 - return
return(MC_estimate)
}
nSamples = 10000
mean = 0
sd = 1
compute_MC_normal_mean(nSamples, mean, sd)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
#
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(fig.align = "center", echo = TRUE)
#
ggplot2::theme_set(ggplot2::theme_bw())
#
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
#
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(fig.align = "center", echo = TRUE)
tumors <- read.csv(file = url("http://www.stat.columbia.edu/~gelman/book/data/rats.asc"),
skip = 2, header = T, sep = " ")[,c(1,2)]
y <- tumors$y
N <- tumors$N
n <- length(y)
head(tumors)
tail(tumors)
plot(seq(0, 1, length.out = 1000),
dbeta(seq(0, 1, length.out = 1000), 1, 1),
type = 'l',
xlab = expression(theta), ylab = "Density",
main = "The Beta(1, 1) density")
stan_dat <- list(n = n, N = N, y =y, a = 1, b = 1)
stan_dat
fit_pool <- stan('lab2_pool.stan', data = stan_dat, chains = 2, refresh = 0)
setwd("/Users/yuqi/Dropbox/Research20/Code/Duke_stats601")
fit_pool <- stan('lab2_pool.stan', data = stan_dat, chains = 2, refresh = 0)
pool_output <- rstan::extract(fit_pool)
mean(pool_output$theta)
hist(pool_output$theta)
?normal_log
??normal_log
setwd("/Users/yuqi/Dropbox/Research20/Works/WithAritra/robust-rpm-public-master/skewnormal")
source("skewnormal.data.R")
# set priors
alpha <- 1 # dirichlet prior on mixture proportions
beta_a <- 1 # beta prior on weights
beta_b <- 0.005
filename <- "skewnormal_wparams.data.R"
stan_rdump(c("N", "D", "K", "X", "alpha",
"beta_a", "beta_b"), filename)
gmm_w_beta <- stan_model(file='gmm_w_beta.stan')
fit_wt <- vb(gmm_w_beta, iter = 80000, eta = 0.5,
tol_rel_obj = 1e-3,
# adapt_engaged = F,
data = read_rdump(filename))
extract(fit_wt)$pi
dim(extract(fit_wt)$pi)
View(extract(fit_wt)$pi)
pi_wt <- colMeans(extract(fit_wt)$pi)
pi_wt
mu_wt <- data.frame(colMeans(extract(fit_wt)$mu)[pi_wt > 0.1,])
mu_wt
data.frame(colMeans(extract(fit_wt)$mu)[pi_wt > 0.01,])
# Count number of proportions larger than 0.01 (3)
print("Reweighted Probabilistic Model")
print("mixture proportions")
print(pi_wt)
print("number of components")
print(sum(pi_wt > 0.1))
0.5/N
print(sum(pi_wt > 0.5/N))
print(sum(pi_wt > 1/sqrt(N))
)
1/sqrt(N)
print(sum(pi_wt > 1/sqrt(N)))
gmm <- stan_model(file='gmm.stan') #unweighted
fit_unwt <- vb(gmm, iter = 80000, eta = 0.5,
tol_rel_obj = 1e-3,
adapt_engaged = F,
data = read_rdump(filename))
pi_unwt <- colMeans(extract(fit_unwt)$pi)
mu_unwt <- data.frame(colMeans(extract(fit_unwt)$mu)[pi_unwt > 0.1,])
# Count number of proportions larger than 0.1 (8-4)
print("Classical Probabilistic Model")
print("mixture proportions")
print(pi_unwt)
print("number of components")
print(sum(pi_unwt > 0.1))
# below we reproduce Fig.4
dat = data.frame(X)
colnames(dat) = c("x1", "x2")
colnames(mu_wt) = c("x1", "x2")
colnames(mu_unwt) = c("x1", "x2")
require(gridExtra)
plot_wt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_wt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Reweighted Model")
colnames(mu_unwt) = c("x1", "x2")
plot_unwt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_unwt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Classical Model")
grid.arrange(plot_wt, plot_unwt, ncol=2)
pi_unwt
pi_wt
pi_wt[pi_wt > 0.1]
pi_unwt[pi_unwt > 0.1]
normalmix <- read.csv(file = 'normalmix.csv')
normalmix
save.image(file="skewnormal.RData")
library(rstan)
# the data is generated from a mixture of
# 3 skewed normal distributions with mixture
# proportions 0.3, 0.3, 0.4
# following the set up in appendix D4.
setwd("/Users/yuqi/Dropbox/Research20/Works/WithAritra/robust-rpm-public-master/skewnormal")
source("normal.data.R")
# set priors
alpha <- 1 # dirichlet prior on mixture proportions
beta_a <- 1 # beta prior on weights
beta_b <- 0.005
filename <- "normal_wparams.data.R"
stan_rdump(c("N", "D", "K", "X", "alpha", "beta_a", "beta_b"), filename)
# Below we fit reweighted GMM and the classical GMM
# by Automatic Differentiation Variational Inference
gmm_w_beta <- stan_model(file='gmm_w_beta.stan')
fit_wt <- vb(gmm_w_beta, iter = 80000, eta = 0.5,
tol_rel_obj = 1e-3,
# adapt_engaged = F,
data = read_rdump(filename))
pi_wt <- colMeans(extract(fit_wt)$pi)
mu_wt <- data.frame(colMeans(extract(fit_wt)$mu)[pi_wt > 0.1,])
# Extract posterior means of mixture proportions (K=30)
# Count number of proportions larger than 0.1 (3)
print("Reweighted Probabilistic Model")
print("mixture proportions")
print(pi_wt)
print("number of components")
print(sum(pi_wt > 0.1))
# print(sum(pi_wt > 1/sqrt(N)))
###################################
# Classical Probabilistic Model
###################################
gmm <- stan_model(file='gmm.stan') #unweighted
fit_unwt <- vb(gmm, iter = 80000, eta = 0.5,
tol_rel_obj = 1e-3,
adapt_engaged = F,
data = read_rdump(filename))
pi_unwt <- colMeans(extract(fit_unwt)$pi)
mu_unwt <- data.frame(colMeans(extract(fit_unwt)$mu)[pi_unwt > 0.1,])
# Extract posterior means of mixture proportions (K=30)
# Count number of proportions larger than 0.1 (8-4)
print("Classical Probabilistic Model")
print("mixture proportions")
print(pi_unwt)
print("number of components")
print(sum(pi_unwt > 0.1))
# there is some randomness in outcomes due to initialization
# may end up with 4-7 components in different runs
# but the number is always larger than the true 3.
# below we reproduce Fig.4
dat = data.frame(X)
colnames(dat) = c("x1", "x2")
colnames(mu_wt) = c("x1", "x2")
colnames(mu_unwt) = c("x1", "x2")
require(gridExtra)
plot_wt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_wt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Reweighted Model")
plot_unwt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_unwt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Classical Model")
grid.arrange(plot_wt, plot_unwt, ncol=2)
pi_wt[pi_wt > 0.1]
pi_unwt[pi_unwt > 0.1]
plot_wt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_wt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Reweighted Model")
plot_unwt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_unwt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Classical Model")
grid.arrange(plot_wt, plot_unwt, ncol=2)
dat
setwd("/Users/yuqi/Dropbox/Research20/Works/WithAritra/robust-rpm-public-master/skewnormal")
source("normal.data.R")
# set priors
alpha <- 1 # dirichlet prior on mixture proportions
beta_a <- 1 # beta prior on weights
beta_b <- 0.005
filename <- "normal_wparams.data.R"
stan_rdump(c("N", "D", "K", "X", "alpha", "beta_a", "beta_b"), filename)
plot_wt = ggplot(dat, aes(x1, x2))
dat = data.frame(X)
colnames(dat) = c("x1", "x2")
plot_wt = ggplot(dat, aes(x1, x2))
plot_wt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray")
View(dat)
library(rstan)
# the data is generated from a mixture of
# 3 skewed normal distributions with mixture
# proportions 0.3, 0.3, 0.4
# following the set up in appendix D4.
setwd("/Users/yuqi/Dropbox/Research20/Works/WithAritra/robust-rpm-public-master/skewnormal")
source("normal.data.R")
# set priors
alpha <- 1 # dirichlet prior on mixture proportions
beta_a <- 1 # beta prior on weights
beta_b <- 0.005
filename <- "normal_wparams.data.R"
stan_rdump(c("N", "D", "K", "X", "alpha", "beta_a", "beta_b"), filename)
# Below we fit reweighted GMM and the classical GMM
# by Automatic Differentiation Variational Inference
###################################
# Reweighted Probabilistic Model
###################################
gmm_w_beta <- stan_model(file='gmm_w_beta.stan')
fit_wt <- vb(gmm_w_beta, iter = 80000, eta = 0.5,
tol_rel_obj = 1e-3,
# adapt_engaged = F,
data = read_rdump(filename))
pi_wt <- colMeans(extract(fit_wt)$pi)
mu_wt <- data.frame(colMeans(extract(fit_wt)$mu)[pi_wt > 0.1,])
# Extract posterior means of mixture proportions (K=30)
# Count number of proportions larger than 0.1 (3)
print("Reweighted Probabilistic Model")
print("mixture proportions")
print(pi_wt)
print("number of components")
print(sum(pi_wt > 0.1))
# print(sum(pi_wt > 1/sqrt(N)))
###################################
# Classical Probabilistic Model
###################################
gmm <- stan_model(file='gmm.stan') #unweighted
fit_unwt <- vb(gmm, iter = 80000, eta = 0.5,
tol_rel_obj = 1e-3,
adapt_engaged = F,
data = read_rdump(filename))
pi_unwt <- colMeans(extract(fit_unwt)$pi)
mu_unwt <- data.frame(colMeans(extract(fit_unwt)$mu)[pi_unwt > 0.1,])
# Extract posterior means of mixture proportions (K=30)
# Count number of proportions larger than 0.1 (8-4)
print("Classical Probabilistic Model")
print("mixture proportions")
print(pi_unwt)
print("number of components")
print(sum(pi_unwt > 0.1))
# there is some randomness in outcomes due to initialization
# may end up with 4-7 components in different runs
# but the number is always larger than the true 3.
# below we reproduce Fig.4
dat = data.frame(X)
colnames(dat) = c("x1", "x2")
colnames(mu_wt) = c("x1", "x2")
colnames(mu_unwt) = c("x1", "x2")
require(gridExtra)
plot_wt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_wt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Reweighted Model")
plot_unwt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_unwt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Classical Model")
grid.arrange(plot_wt, plot_unwt, ncol=2)
pi_wt[pi_wt > 0.1]
pi_unwt[pi_unwt > 0.1]
plot_wt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_wt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Reweighted Model")
plot_unwt = ggplot(dat, aes(x1, x2)) + geom_point(color = "gray") +
geom_point(data = mu_unwt, aes(x1, x2),
shape = 4, size = 8) + ggtitle("Classical Model")
grid.arrange(plot_wt, plot_unwt, ncol=2)
pi_wt
pi_unwt
save.image(file = "normalmix.RData")
install.packages("corels")
library(corels)
logdir <- tempdir()
rules_file <- system.file("sample_data", "compas_train.out", package="corels")
rules_file
View(rules_file)
labels_file <- system.file("sample_data", "compas_train.label", package="corels")
meta_file <- system.file("sample_data", "compas_train.minor", package="corels")
stopifnot(file.exists(rules_file),
file.exists(labels_file),
file.exists(meta_file),
dir.exists(logdir))
corels(rules_file, labels_file, logdir, meta_file,
verbosity_policy = "silent",
regularization = 0.015,
curiosity_policy = 2, # by lower bound
map_type = 1) # permutation map
cat("See ", logdir, " for result file.")
sample_data
logdir <- setwd("/Users/yuqi/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/corels")
rules_file <- system.file("sample_data", "compas_train.out", package="corels")
labels_file <- system.file("sample_data", "compas_train.label", package="corels")
meta_file <- system.file("sample_data", "compas_train.minor", package="corels")
stopifnot(file.exists(rules_file),
file.exists(labels_file),
file.exists(meta_file),
dir.exists(logdir))
corels(rules_file, labels_file, logdir, meta_file,
verbosity_policy = "silent",
regularization = 0.015,
curiosity_policy = 2, # by lower bound
map_type = 1) # permutation map
cat("See ", logdir, " for result file.")
setwd("/Users/yuqi/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/corels")
logdir <- tempdir("/Users/yuqi/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/corels")
rules_file <- system.file("sample_data", "compas_train.out", package="corels")
labels_file <- system.file("sample_data", "compas_train.label", package="corels")
meta_file <- system.file("sample_data", "compas_train.minor", package="corels")
stopifnot(file.exists(rules_file),
file.exists(labels_file),
file.exists(meta_file),
dir.exists(logdir))
corels(rules_file, labels_file, logdir, meta_file,
verbosity_policy = "silent",
regularization = 0.015,
curiosity_policy = 2, # by lower bound
map_type = 1) # permutation map
cat("See ", logdir, " for result file.")
setwd("/Users/yuqi/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/corels")
source('~/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/R_code/corels.R', echo=TRUE)
tempdir()
logdir <- "/Users/yuqi/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/corels"
logdir
source('~/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/R_code/corels.R', echo=TRUE)
"sample_data"
rules_file
setwd("/Users/yuqi/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/corels")
logdir <- "/Users/yuqi/Dropbox/Research20/Postdoc/work_multi_layer/MultLayer_CODE/corels"
# logdir <- tempdir()
rules_file <-  system.file("sample_data", "compas_train.out", package="corels")
labels_file <- system.file("sample_data", "compas_train.label", package="corels")
meta_file <- system.file("sample_data", "compas_train.minor", package="corels")
stopifnot(file.exists(rules_file),
file.exists(labels_file),
file.exists(meta_file),
dir.exists(logdir))
corels(rules_file, labels_file, logdir, meta_file,
verbosity_policy = "silent",
regularization = 0.015,
curiosity_policy = 2, # by lower bound
map_type = 1) # permutation map
cat("See ", logdir, " for result file.")
mylist = corels(rules_file, labels_file, logdir, meta_file,
verbosity_policy = "silent",
regularization = 0.015,
curiosity_policy = 2, # by lower bound
map_type = 1) # permutation map
mylist
